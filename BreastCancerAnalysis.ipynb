{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "BreastCancerAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zprd87Lc12P_"
      },
      "source": [
        "# This was a coding test that I got,where we were given an imbalanced dataset to perform classsification.\r\n",
        "#Thank you for reviweing it."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Lkw5Ph12QN"
      },
      "source": [
        "# Load libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu3Dm04J12QO",
        "outputId": "06fd60b2-6a9f-4417-c8d8-2b284e22c8f8"
      },
      "source": [
        "#reading data\n",
        "data=pd.read_csv('../data/breastCancer.csv')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1065, 3005)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_q4Zby12QR",
        "outputId": "c7c94444-6a45-48bd-bb09-3c977ccc1e57"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENSG00000238009.5</th>\n",
              "      <th>ENSG00000239945.1</th>\n",
              "      <th>ENSG00000239906.1</th>\n",
              "      <th>ENSG00000241860.5</th>\n",
              "      <th>ENSG00000241599.1</th>\n",
              "      <th>ENSG00000228463.7</th>\n",
              "      <th>ENSG00000237094.10</th>\n",
              "      <th>ENSG00000231709.1</th>\n",
              "      <th>ENSG00000235146.2</th>\n",
              "      <th>ENSG00000239664.2</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260066.1</th>\n",
              "      <th>ENSG00000249966.1</th>\n",
              "      <th>ENSG00000250417.1</th>\n",
              "      <th>ENSG00000249116.1</th>\n",
              "      <th>ENSG00000249326.1</th>\n",
              "      <th>ENSG00000248994.1</th>\n",
              "      <th>ENSG00000248597.1</th>\n",
              "      <th>ENSG00000249731.1</th>\n",
              "      <th>ENSG00000259757.1</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.066580</td>\n",
              "      <td>0.010619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016603</td>\n",
              "      <td>0.058506</td>\n",
              "      <td>0.025905</td>\n",
              "      <td>0.034251</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457670</td>\n",
              "      <td>0.050529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.616618</td>\n",
              "      <td>0.116334</td>\n",
              "      <td>0.754627</td>\n",
              "      <td>0.169331</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.031641</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005481</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147452</td>\n",
              "      <td>0.046222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.694184</td>\n",
              "      <td>0.085048</td>\n",
              "      <td>0.045365</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018166</td>\n",
              "      <td>0.073513</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.015551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.056154</td>\n",
              "      <td>0</td>\n",
              "      <td>0.704467</td>\n",
              "      <td>0.063171</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159474</td>\n",
              "      <td>0.309376</td>\n",
              "      <td>0.061996</td>\n",
              "      <td>0.041399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.006670</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.085850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.109156</td>\n",
              "      <td>0.162077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.361059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184089</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1060</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012672</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.130767</td>\n",
              "      <td>0.036830</td>\n",
              "      <td>0.099515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1061</th>\n",
              "      <td>0.043179</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317558</td>\n",
              "      <td>0.124022</td>\n",
              "      <td>0.111923</td>\n",
              "      <td>0.050543</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106333</td>\n",
              "      <td>0.065166</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091958</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062</th>\n",
              "      <td>0.196910</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093311</td>\n",
              "      <td>0.177519</td>\n",
              "      <td>0.160484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.014497</td>\n",
              "      <td>0.494752</td>\n",
              "      <td>0.094095</td>\n",
              "      <td>0.122284</td>\n",
              "      <td>0.132247</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>0.008062</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090375</td>\n",
              "      <td>0.152158</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172159</td>\n",
              "      <td>0.204781</td>\n",
              "      <td>0.069838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033532</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.022836</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>0.013687</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063383</td>\n",
              "      <td>0.062773</td>\n",
              "      <td>0.030112</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.059058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.207734</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1065 rows × 3005 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ENSG00000238009.5  ENSG00000239945.1  ENSG00000239906.1  \\\n",
              "0              0.000000                  0           0.066580   \n",
              "1              0.005481                  0           0.000000   \n",
              "2              0.000000                  0           0.000000   \n",
              "3              0.056154                  0           0.704467   \n",
              "4              0.006670                  0           0.000000   \n",
              "...                 ...                ...                ...   \n",
              "1060           0.000000                  0           0.000000   \n",
              "1061           0.043179                  0           0.000000   \n",
              "1062           0.196910                  0           0.000000   \n",
              "1063           0.008062                  0           0.090375   \n",
              "1064           0.013687                  0           0.000000   \n",
              "\n",
              "      ENSG00000241860.5  ENSG00000241599.1  ENSG00000228463.7  \\\n",
              "0              0.010619                0.0           0.016603   \n",
              "1              0.035883                0.0           0.147452   \n",
              "2              0.023149                0.0           0.018166   \n",
              "3              0.063171                0.0           0.159474   \n",
              "4              0.085850                0.0           0.109156   \n",
              "...                 ...                ...                ...   \n",
              "1060           0.000000                0.0           0.000000   \n",
              "1061           0.020938                0.0           0.317558   \n",
              "1062           0.022889                0.0           0.093311   \n",
              "1063           0.152158                0.0           0.172159   \n",
              "1064           0.084335                0.0           0.063383   \n",
              "\n",
              "      ENSG00000237094.10  ENSG00000231709.1  ENSG00000235146.2  \\\n",
              "0               0.058506           0.025905           0.034251   \n",
              "1               0.046222           0.000000           0.000000   \n",
              "2               0.073513           0.000000           0.000000   \n",
              "3               0.309376           0.061996           0.041399   \n",
              "4               0.162077           0.000000           0.000000   \n",
              "...                  ...                ...                ...   \n",
              "1060            0.012672           0.000000           0.000000   \n",
              "1061            0.124022           0.111923           0.050543   \n",
              "1062            0.177519           0.160484           0.000000   \n",
              "1063            0.204781           0.069838           0.000000   \n",
              "1064            0.062773           0.030112           0.000000   \n",
              "\n",
              "      ENSG00000239664.2  ...  ENSG00000260066.1  ENSG00000249966.1  \\\n",
              "0                   0.0  ...           0.457670           0.050529   \n",
              "1                   0.0  ...           0.000000           0.000000   \n",
              "2                   0.0  ...           0.047030           0.000000   \n",
              "3                   0.0  ...           0.000000           0.000000   \n",
              "4                   0.0  ...           0.000000           0.000000   \n",
              "...                 ...  ...                ...                ...   \n",
              "1060                0.0  ...           0.000000           0.000000   \n",
              "1061                0.0  ...           0.000000           0.000000   \n",
              "1062                0.0  ...           0.007856           0.000000   \n",
              "1063                0.0  ...           0.009928           0.000000   \n",
              "1064                0.0  ...           0.000000           0.000000   \n",
              "\n",
              "      ENSG00000250417.1  ENSG00000249116.1  ENSG00000249326.1  \\\n",
              "0                   0.0           2.616618           0.116334   \n",
              "1                   0.0           1.694184           0.085048   \n",
              "2                   0.0           1.015551           0.000000   \n",
              "3                   0.0           0.000000           0.016220   \n",
              "4                   0.0           0.361059           0.000000   \n",
              "...                 ...                ...                ...   \n",
              "1060                0.0           3.130767           0.036830   \n",
              "1061                0.0           0.000000           0.000000   \n",
              "1062                0.0           0.208400           0.014497   \n",
              "1063                0.0           0.000000           0.000000   \n",
              "1064                0.0           0.059058           0.000000   \n",
              "\n",
              "      ENSG00000248994.1  ENSG00000248597.1  ENSG00000249731.1  \\\n",
              "0              0.754627           0.169331           0.038777   \n",
              "1              0.045365           0.000000           0.000000   \n",
              "2              0.129658           0.000000           0.083580   \n",
              "3              0.000000           0.000000           0.000000   \n",
              "4              0.184089           0.000000           0.043807   \n",
              "...                 ...                ...                ...   \n",
              "1060           0.099515           0.000000           0.000000   \n",
              "1061           0.106333           0.065166           0.000000   \n",
              "1062           0.494752           0.094095           0.122284   \n",
              "1063           0.033532           0.000000           0.000000   \n",
              "1064           0.084059           0.000000           0.000000   \n",
              "\n",
              "      ENSG00000259757.1  TARGET  \n",
              "0              0.031641       0  \n",
              "1              0.000000       0  \n",
              "2              0.000000       0  \n",
              "3              0.000000       0  \n",
              "4              0.000000       0  \n",
              "...                 ...     ...  \n",
              "1060           0.000000       3  \n",
              "1061           0.091958       3  \n",
              "1062           0.132247       3  \n",
              "1063           1.022836       3  \n",
              "1064           0.207734       3  \n",
              "\n",
              "[1065 rows x 3005 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AAAaRNJZ12QR",
        "outputId": "19ce460e-5963-48c1-ce6d-2bdfa9e6c60f"
      },
      "source": [
        "# class distribution of the last columns -- 'TARGET'\n",
        "print(data.groupby('TARGET').size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TARGET\n",
            "0    191\n",
            "1     81\n",
            "2    577\n",
            "3    216\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lSiVncV12QT"
      },
      "source": [
        "As we can see the data seems unbalanced.So, we can apply SMOTE for making the data balanced.\n",
        "Before applying SMOTE I have applied PCA to get away from the curse of dimensionality.\n",
        "After that I have done some feature selection. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRL0OOUX12QU",
        "outputId": "e451f03a-63fc-4565-d6a6-8182737b3c4e"
      },
      "source": [
        "# Split into training and test datasets: 80-20 split\n",
        "array = data.values\n",
        "X = array[:,0:len(data.columns)-1]\n",
        "y = data[['TARGET']]\n",
        "y = y.to_numpy()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(852, 3004) (852, 1) (213, 3004) (213, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_keJcml12QV"
      },
      "source": [
        "Performing Feature selection and using score_func as f_classif which is computing the ANOVA F-value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KSgBiy-12QW",
        "outputId": "061e8553-8326-4d9a-f773-4820c17320f2"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "fs = SelectKBest(score_func = f_classif, k = 'all')\n",
        "fs.fit(X_train, Y_train)\n",
        "X_train_fs = fs.transform(X_train)\n",
        "X_test_fs = fs.transform(X_test)\n",
        "X_train_fs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   1  197  510  607  618  846  980 1211 1619 2183 2569] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03178003, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.03439096],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.01208877, 0.        , 0.06837251, ..., 0.        , 0.        ,\n",
              "        0.03250319],\n",
              "       ...,\n",
              "       [0.00525774, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.14828733, ..., 0.05057737, 0.        ,\n",
              "        0.17255884],\n",
              "       [0.04317937, 0.        , 0.        , ..., 0.06516629, 0.        ,\n",
              "        0.09195841]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfkAyCeQ12QX"
      },
      "source": [
        "Selecting top N features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tcwmdZKd12QY",
        "outputId": "3af0b263-d804-4df0-e1d5-79d560de5e2a"
      },
      "source": [
        "s = pd.Series(fs.scores_)\n",
        "s.nlargest(5)\n",
        "\n",
        "N = 5\n",
        "columnNames2 = ['score', 'indx', 'name']\n",
        "sdf = pd.DataFrame(columns = columnNames2)\n",
        "sdf['score'] = pd.Series(fs.scores_).nlargest(N)\n",
        "sdf['indx'] = sdf.index.values\n",
        "for counter in sdf.index.values:\n",
        "    sdf.at[counter,'name'] = data.columns[counter]\n",
        "    # df.at['C', 'x'] = 10\n",
        "sdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>indx</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1576</th>\n",
              "      <td>416.198778</td>\n",
              "      <td>1576</td>\n",
              "      <td>ENSG00000258910.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>279.801241</td>\n",
              "      <td>2702</td>\n",
              "      <td>ENSG00000248360.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2238</th>\n",
              "      <td>238.643263</td>\n",
              "      <td>2238</td>\n",
              "      <td>ENSG00000239445.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>210.181905</td>\n",
              "      <td>1285</td>\n",
              "      <td>ENSG00000231367.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1300</th>\n",
              "      <td>191.268212</td>\n",
              "      <td>1300</td>\n",
              "      <td>ENSG00000231826.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           score  indx               name\n",
              "1576  416.198778  1576  ENSG00000258910.2\n",
              "2702  279.801241  2702  ENSG00000248360.6\n",
              "2238  238.643263  2238  ENSG00000239445.4\n",
              "1285  210.181905  1285  ENSG00000231367.4\n",
              "1300  191.268212  1300  ENSG00000231826.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d6lRiL012QZ"
      },
      "source": [
        "columnNames = []\n",
        "for counter in sdf.index.values:\n",
        "    columnNames.append(sdf.at[counter,'name']) \n",
        "# columnNames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4AMsBOd12QZ",
        "outputId": "b0d8ac8f-38e2-491d-abf1-59c2875b1fb5"
      },
      "source": [
        "df = pd.DataFrame(columns = columnNames)\n",
        "for counter in sdf.index.values:\n",
        "    # print(sdf.at[counter,'name'])\n",
        "    df[sdf.at[counter,'name']] = pd.Series(data[sdf.at[counter,'name']])\n",
        "# df['TARGET'] = pd.Series(data['TARGET'])\n",
        "df\n",
        "# df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENSG00000258910.2</th>\n",
              "      <th>ENSG00000248360.6</th>\n",
              "      <th>ENSG00000239445.4</th>\n",
              "      <th>ENSG00000231367.4</th>\n",
              "      <th>ENSG00000231826.4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.562450</td>\n",
              "      <td>0.029926</td>\n",
              "      <td>0.983485</td>\n",
              "      <td>0.446161</td>\n",
              "      <td>0.031561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.735789</td>\n",
              "      <td>0.039612</td>\n",
              "      <td>0.919689</td>\n",
              "      <td>1.691606</td>\n",
              "      <td>0.043826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.707383</td>\n",
              "      <td>0.096038</td>\n",
              "      <td>1.193897</td>\n",
              "      <td>2.290346</td>\n",
              "      <td>0.374735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.473198</td>\n",
              "      <td>0.036183</td>\n",
              "      <td>0.361846</td>\n",
              "      <td>1.785187</td>\n",
              "      <td>1.596191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.034735</td>\n",
              "      <td>0.103733</td>\n",
              "      <td>0.029249</td>\n",
              "      <td>1.543009</td>\n",
              "      <td>4.333071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1060</th>\n",
              "      <td>0.265387</td>\n",
              "      <td>1.139576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178258</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1061</th>\n",
              "      <td>0.100445</td>\n",
              "      <td>0.476171</td>\n",
              "      <td>0.111795</td>\n",
              "      <td>0.428418</td>\n",
              "      <td>0.784202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062</th>\n",
              "      <td>0.073938</td>\n",
              "      <td>1.561187</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.387580</td>\n",
              "      <td>0.075687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>1.120905</td>\n",
              "      <td>1.540931</td>\n",
              "      <td>0.136296</td>\n",
              "      <td>0.145736</td>\n",
              "      <td>0.053586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>0.053396</td>\n",
              "      <td>1.511376</td>\n",
              "      <td>0.224694</td>\n",
              "      <td>0.056831</td>\n",
              "      <td>0.374163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1065 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ENSG00000258910.2  ENSG00000248360.6  ENSG00000239445.4  \\\n",
              "0              2.562450           0.029926           0.983485   \n",
              "1              2.735789           0.039612           0.919689   \n",
              "2              2.707383           0.096038           1.193897   \n",
              "3              2.473198           0.036183           0.361846   \n",
              "4              2.034735           0.103733           0.029249   \n",
              "...                 ...                ...                ...   \n",
              "1060           0.265387           1.139576           0.000000   \n",
              "1061           0.100445           0.476171           0.111795   \n",
              "1062           0.073938           1.561187           0.108823   \n",
              "1063           1.120905           1.540931           0.136296   \n",
              "1064           0.053396           1.511376           0.224694   \n",
              "\n",
              "      ENSG00000231367.4  ENSG00000231826.4  \n",
              "0              0.446161           0.031561  \n",
              "1              1.691606           0.043826  \n",
              "2              2.290346           0.374735  \n",
              "3              1.785187           1.596191  \n",
              "4              1.543009           4.333071  \n",
              "...                 ...                ...  \n",
              "1060           0.178258           0.000000  \n",
              "1061           0.428418           0.784202  \n",
              "1062           0.387580           0.075687  \n",
              "1063           0.145736           0.053586  \n",
              "1064           0.056831           0.374163  \n",
              "\n",
              "[1065 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WMJkzXM12Qa"
      },
      "source": [
        "After completing feature selection we select the top N features which  are listed above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEpsnhmz12Qa"
      },
      "source": [
        "Performing SMOTE to deal with the imbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rHgRExZV12Qb",
        "outputId": "71dd12b8-740e-41db-918f-e22d889f880a"
      },
      "source": [
        "array = df.values\n",
        "X = array[:,2:6]\n",
        "y = pd.Series(data['TARGET'])\n",
        "y = y.to_numpy()\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# ploting the above\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class=0, n=577 (25.000%)\n",
            "Class=1, n=577 (25.000%)\n",
            "Class=2, n=577 (25.000%)\n",
            "Class=3, n=577 (25.000%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g846e17G12Qc",
        "outputId": "e9b778d0-d76e-48ec-918a-7671ef800054"
      },
      "source": [
        "#normalizing the data\n",
        "from sklearn.preprocessing import normalize\n",
        "df3 = pd.DataFrame(normalize(df)) # ,columns = columnNames)\n",
        "df3['TARGET'] = pd.Series(data['TARGET'])\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.921390</td>\n",
              "      <td>0.010761</td>\n",
              "      <td>0.353636</td>\n",
              "      <td>0.160428</td>\n",
              "      <td>0.011349</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.817642</td>\n",
              "      <td>0.011839</td>\n",
              "      <td>0.274866</td>\n",
              "      <td>0.505568</td>\n",
              "      <td>0.013098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.719717</td>\n",
              "      <td>0.025530</td>\n",
              "      <td>0.317379</td>\n",
              "      <td>0.608854</td>\n",
              "      <td>0.099617</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.714437</td>\n",
              "      <td>0.010452</td>\n",
              "      <td>0.104527</td>\n",
              "      <td>0.515690</td>\n",
              "      <td>0.461094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.404462</td>\n",
              "      <td>0.020620</td>\n",
              "      <td>0.005814</td>\n",
              "      <td>0.306717</td>\n",
              "      <td>0.861322</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1060</th>\n",
              "      <td>0.224226</td>\n",
              "      <td>0.962829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1061</th>\n",
              "      <td>0.098125</td>\n",
              "      <td>0.465174</td>\n",
              "      <td>0.109213</td>\n",
              "      <td>0.418524</td>\n",
              "      <td>0.766091</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062</th>\n",
              "      <td>0.045761</td>\n",
              "      <td>0.966247</td>\n",
              "      <td>0.067353</td>\n",
              "      <td>0.239880</td>\n",
              "      <td>0.046844</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>0.584822</td>\n",
              "      <td>0.803967</td>\n",
              "      <td>0.071111</td>\n",
              "      <td>0.076036</td>\n",
              "      <td>0.027958</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>0.033901</td>\n",
              "      <td>0.959565</td>\n",
              "      <td>0.142657</td>\n",
              "      <td>0.036082</td>\n",
              "      <td>0.237554</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1065 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4  TARGET\n",
              "0     0.921390  0.010761  0.353636  0.160428  0.011349       0\n",
              "1     0.817642  0.011839  0.274866  0.505568  0.013098       0\n",
              "2     0.719717  0.025530  0.317379  0.608854  0.099617       0\n",
              "3     0.714437  0.010452  0.104527  0.515690  0.461094       0\n",
              "4     0.404462  0.020620  0.005814  0.306717  0.861322       0\n",
              "...        ...       ...       ...       ...       ...     ...\n",
              "1060  0.224226  0.962829  0.000000  0.150610  0.000000       3\n",
              "1061  0.098125  0.465174  0.109213  0.418524  0.766091       3\n",
              "1062  0.045761  0.966247  0.067353  0.239880  0.046844       3\n",
              "1063  0.584822  0.803967  0.071111  0.076036  0.027958       3\n",
              "1064  0.033901  0.959565  0.142657  0.036082  0.237554       3\n",
              "\n",
              "[1065 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIEe0k_c12Qe"
      },
      "source": [
        "array = df.values\n",
        "X = array[:,0:4]\n",
        "y= array[:,4]\n",
        "#y=y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBV839kr12Qe"
      },
      "source": [
        "\n",
        "\n",
        "As we can see from above and through the graph it is clear that data is now balanced.\n",
        "After dealing with the imbalanced data, now applying some machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKS92c_h12Qf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nS5rGKX12Qh"
      },
      "source": [
        "# Spot Check Algorithms\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver = 'liblinear', multi_class = 'ovr')))\n",
        "# models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "# models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "# models.append(('SVM', SVC(gamma='auto')))\n",
        "models.append(('NN', MLPClassifier(solver = 'lbfgs')))\n",
        "# models.append(('RF',RandomForestClassifier(max_depth=2)))\n",
        "models.append(('ADB', AdaBoostClassifier(n_estimators = 100)))\n",
        "# models.append(('QDA',QuadraticDiscriminantAnalysis()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s03eG3vb12Qi",
        "outputId": "dc3b6731-3e41-481a-dfd2-a16f37816ce1"
      },
      "source": [
        "# evaluate each model in turn, but only with training data set using 10-fold CV\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
        "\tcv_results = cross_val_score(model, X_train, Y_train, cv = kfold, scoring = 'accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR: 0.880260 (0.026806)\n",
            "CART: 0.720670 (0.036228)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NB: 0.578687 (0.041337)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NN: 0.870862 (0.021190)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n",
            "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ADB: 0.637319 (0.068195)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFBSFGxu12Qj",
        "outputId": "431c6129-addd-4fe8-b6a9-2f8fb4e5b887"
      },
      "source": [
        "# Compare Algorithms\n",
        "plt.boxplot(results, labels=names)\n",
        "plt.title('Algorithm Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHnMZWzL12Qk"
      },
      "source": [
        "# Implementing Decision Tree classifier\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
        "model.fit(X_train, Y_train)\n",
        "predictions=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dca2kMAr12Qk",
        "outputId": "a2fd66c6-2720-490a-83d5-b384f7db945a"
      },
      "source": [
        "# Evaluate predictions -- this is done only on the test set\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(Y_test, predictions))\n",
        "print(confusion_matrix(Y_test, predictions))\n",
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7323943661971831\n",
            "[[42  0  4  0]\n",
            " [ 1  5  8  8]\n",
            " [ 0  0 89 14]\n",
            " [ 0  0 22 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94        46\n",
            "           1       1.00      0.23      0.37        22\n",
            "           2       0.72      0.86      0.79       103\n",
            "           3       0.48      0.48      0.48        42\n",
            "\n",
            "    accuracy                           0.73       213\n",
            "   macro avg       0.79      0.62      0.64       213\n",
            "weighted avg       0.76      0.73      0.72       213\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFv549Qn12Qo"
      },
      "source": [
        "The ML methods used are:  LogisticRegression, DecisionTreeClassifier, GaussianNB, MLP Classifier(Neural Network), and AdaBoost Classifier. \r\n",
        "I did outlier removal and PCA(to get away from the curse of dimensionality) but eventually did not include them since they were not affecting the accuracy at all. I believe that since the data comprises of genes so the accuracy might improve by taking differentially expressed genes as features for classification.However, this requires some in depth research on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iukqy4CY12Qp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}